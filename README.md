# MobileNetV1-V3

## Overview
A course project on MobileNet, with mathematical explanation and experiments (reimplementation).

What is the key that makes MobileNet a mainstream for mobile vision with fewer parameters but great performance? A general answer is the use of depth-wise separable convolutions, inverted residual blocks, and squeeze and excitation blocks. These elements play a critical role in building lightweight, low latency deep neural networks for mobile and embedded devices.
In this paper, we look into mathematical foundations for depth-wise separable convolutions and inverted residual blocks. We state out theorems and provide explanations of the key elements in MobileNet and conduct experiment for image classification task on CIFAR-10, Flower and other datasets.
The experiment results show that MobileNet achieves considerate accuracy in image classification tasks comparing to other neural networks with greater parameters, which justify its ability of maintaining good performance on mobile devices with less computational resource and less energy consumption.

## Team 
This is a project of 4 members.
##### Xin Huang xh2510@columbia.edu
##### Qimeng Tao qt2139@columbia.edu
##### Andreas Knaupp andreas.knaupp@columbia.eduÂ 
##### Ling Sun ls3759@columbia.edu

